{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d85d4d5-f588-4945-884b-b72007143eee",
   "metadata": {},
   "source": [
    "## Attention\n",
    "\n",
    "\n",
    "Attention = 注意力，从两个不同的主体开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bdde2-596b-4b6d-b9ee-9d23314d70be",
   "metadata": {},
   "source": [
    "### 直观理解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba8a89-0900-4564-9af1-ab675af8b79e",
   "metadata": {},
   "source": [
    "![](./resource/seq2seq.jpg)\n",
    "\n",
    "From：https://arxiv.org/pdf/1703.03906.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de78f4a-e521-468a-8b91-3d59b4f4c748",
   "metadata": {},
   "source": [
    "![](./resource/seq2seq2.gif)\n",
    "\n",
    "From: https://github.com/google/seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab7cd3-d95c-47ba-ac9e-6437c7dfd61e",
   "metadata": {},
   "source": [
    "### 如何计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461d3ae-a7f7-4858-b739-f0b8a785b393",
   "metadata": {},
   "source": [
    "加性Attention，如（Bahdanau attention）：\n",
    "\n",
    "$$\n",
    "\\boldsymbol{v}_a^{\\top} \\tanh \\left(\\boldsymbol{W}_{\\mathbf{1}} \\boldsymbol{h}_t+\\boldsymbol{W}_{\\mathbf{2}} \\overline{\\boldsymbol{h}}_s\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e319aa-f9d1-4eb7-8969-4c64b21d888e",
   "metadata": {},
   "source": [
    "乘性Attention，如（Luong attention）：\n",
    "\n",
    "$$\n",
    "\\operatorname{score}\\left(\\boldsymbol{h}_{t}, \\overline{\\boldsymbol{h}}_{s}\\right)=\\left\\{\\begin{array}{ll}\n",
    "\\boldsymbol{h}_{t}^{\\top} \\overline{\\boldsymbol{h}}_{s} & \\text { dot } \\\\\n",
    "\\boldsymbol{h}_{t}^{\\top} \\boldsymbol{W}_{a} \\overline{\\boldsymbol{h}}_{s} & \\text { general } \\\\\n",
    "\\boldsymbol{v}_{a}^{\\top} \\tanh \\left(\\boldsymbol{W}_{a}\\left[\\boldsymbol{h}_{t} ; \\overline{\\boldsymbol{h}}_{s}\\right]\\right) & \\text { concat }\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6e194-6c39-49af-ba1b-bc5e2a40d160",
   "metadata": {},
   "source": [
    "From: https://arxiv.org/pdf/1508.04025.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d317bb",
   "metadata": {},
   "source": [
    "## From Attention to SelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235bbd7-7766-40c5-a294-db420394c8d0",
   "metadata": {},
   "source": [
    "### Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1816b8f-057d-4ae0-95f2-7ff80f5bceaa",
   "metadata": {},
   "source": [
    "\"Attention is All You Need\" 这篇论文提出了Multi-Head Self-Attention，是一种：Scaled Dot-Product Attention。\n",
    "\n",
    "$$\n",
    "\\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "From：https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61706850-b760-430e-9168-723a62ba2aa6",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657165f-373e-46d6-bdbf-8852fdccf3ad",
   "metadata": {},
   "source": [
    "Scaled 的目的是调节内积，使其结果不至于太大（太大的话softmax后就非0即1了，不够“soft”了）。\n",
    "\n",
    "From: https://kexue.fm/archives/4765"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6cb27b-aaa2-4060-a307-def35fa9c965",
   "metadata": {},
   "source": [
    "### Multi-Head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33dbf7-0a5b-4607-8cca-e5c302ef0355",
   "metadata": {},
   "source": [
    "\n",
    "Multi-Head可以理解为多个注意力模块，期望不同注意力模块“注意”到不一样的地方，类似于CNN的Kernel。\n",
    "\n",
    ">Multi-head attention allows the model to jointly attend to information from different representation\n",
    "subspaces at different positions.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{MultiHead}(Q, K, V) & =\\operatorname{Concat}\\left(\\operatorname{head}_1, \\ldots, \\text { head }_{\\mathrm{h}}\\right) W^O \\\\\n",
    "\\text { where head }_{\\mathrm{i}} & =\\operatorname{Attention}\\left(Q W_i^Q, K W_i^K, V W_i^V\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "From: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5249a-7d46-4462-a419-55490fd2fb8f",
   "metadata": {},
   "source": [
    "## 实践体验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fe44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e99f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selfattention import SelfAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75232767-9de8-40f3-ae40-7623f19670db",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc475ae7-f3cb-44cb-9f37-4aadbe8c0e3b",
   "metadata": {},
   "source": [
    "我们只用一个核心的SelfAttention模块（可支持Single-Head或Multi-Head），来学习理解Attention机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c39436-3cbb-4f1e-ab6b-6a391e9cf857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.emb = nn.Embedding(config.vocab_size, config.hidden_dim)\n",
    "        self.attn = SelfAttention(config)\n",
    "        self.fc = nn.Linear(config.hidden_dim, config.num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        h = self.emb(x)\n",
    "        attn_score, h = self.attn(h)\n",
    "        h = F.avg_pool1d(h.permute(0, 2, 1), seq_len, 1)\n",
    "        h = h.squeeze(-1)\n",
    "        logits = self.fc(h)\n",
    "        return attn_score, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005647c-52e8-4061-b245-e9ae5f26985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \n",
    "    vocab_size: int = 5000\n",
    "    hidden_dim: int = 512\n",
    "    num_heads: int = 16\n",
    "    head_dim: int = 32\n",
    "    dropout: float = 0.1\n",
    "    \n",
    "    num_labels: int = 2\n",
    "    \n",
    "    max_seq_len: int = 512\n",
    "    \n",
    "    num_epochs: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02591051-1b4a-455f-9062-9f6207c96ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(5000, 512, 16, 32, 0.1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535143a-07f2-4c4c-ba30-fd99ded16c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa87885-35a6-40a7-a166-f000c93aca0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randint(0, 5000, (3, 30))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3e4f5-cabf-43e5-b968-911e12572cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn, logits = model(x)\n",
    "attn.shape, logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc470104-084f-4e28-91ca-dd73ca296860",
   "metadata": {},
   "source": [
    "### 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e821d-0104-401a-b88f-cfbd8117ed7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff42551-409c-45a1-8442-4ac6bcbc99da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"./data/ChnSentiCorp_htl_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d38b87-c6d7-4d08-bf14-3cd83f42c17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df.dropna()\n",
    "df.head(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90606c63-697c-436c-8797-f00d166f9848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a663c2-f465-4874-a016-94087caf5d30",
   "metadata": {},
   "source": [
    "数据不均衡，我们给它简单重采样一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f87df-965d-4d2d-bd60-26d90b29c605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df[df.label==1].sample(2500), df[df.label==0]])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe2431-7417-49fa-a00e-a82ca41d2ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120f5c7-e289-474b-a33d-3cd4f5462d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecffd92-8999-4505-bbeb-10adf0eae523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(config.vocab_size, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21660408-b951-40d6-83d7-bd51cf9c3e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.build_vocab(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5e33e-9d41-438e-b53e-b1f6a5af5fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer([\"你好\", \"你好呀\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c9ef9-3971-4a36-946a-72858c6318b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for v in batch:\n",
    "        _label = v[\"label\"]\n",
    "        _text = v[\"text\"]\n",
    "        label_list.append(_label)\n",
    "        text_list.append(_text)\n",
    "    inputs = tokenizer(text_list)\n",
    "    labels = torch.LongTensor(label_list)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70359697-6afe-408e-8238-d43f07d9d504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a93a3a-b700-4ec1-89d2-d609a8204db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "ds.build(df, \"review\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d655ca-69ee-4b93-80e8-1f1db3d0c869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(ds), ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba47c53-1538-4086-ae94-2def8dcde714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds = train_test_split(ds, test_size=0.2)\n",
    "train_ds, valid_ds = train_test_split(train_ds, test_size=0.1)\n",
    "len(train_ds), len(valid_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde81cb-bac0-4724-8786-abfe9ed6c1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd0605-0535-4c9c-bf3e-f79fde020ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ed2e2-1b43-4f84-bd0c-3a08a2d6d4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "len(train_dl), len(valid_dl), len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4a31b-d992-4db5-b4d5-b8f1572099b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for v in train_dl: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c7a89-02e8-406a-9b63-b72815f0253c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v[0].shape, v[1].shape, v[0].dtype, v[1].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bfbf8-e11a-4694-b0d3-e2c0fab0218b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e0e2a-7092-4e62-b51a-c330f9f20fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trainer import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d64474-5703-4f7c-a8a9-9b3011d1b7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = Config(5000, 64, 1, 64, 0.1, 2)\n",
    "model = Model(config)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "train(model, optimizer, train_dl, valid_dl, config)\n",
    "\n",
    "test(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48c43a-d5f1-4a05-b54b-41973b318af2",
   "metadata": {},
   "source": [
    "### 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f159c-d1f2-49b1-8c82-0e4f9aa5f6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inference import infer, plot_attention\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae1a2c-4697-4b97-a8df-ca468d1ba319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = np.random.choice(test_ds)\n",
    "while len(sample[\"text\"]) > 20:\n",
    "    sample = np.random.choice(test_ds)\n",
    "\n",
    "print(sample)\n",
    "\n",
    "inp = sample[\"text\"]\n",
    "inputs = tokenizer(inp)\n",
    "attn, prob = infer(model, inputs.to(device))\n",
    "attn_prob = attn[0, 0, :, :].cpu().numpy()\n",
    "tokens = tokenizer.tokenize(inp)\n",
    "tokens, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c132371-62ef-4381-b97e-74b32d48e547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_attention(attn_prob, tokens, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c7bd2-17f7-4f71-b3fe-51b6dc88566e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.get_freq_of(\"不\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965479d-e696-4845-b80e-5c92f6ace924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
