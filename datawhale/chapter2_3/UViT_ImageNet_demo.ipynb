{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d83bd8-f0ae-4118-8005-ada7d8b0b3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/baofff/U-ViT\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57ae81-d9fa-4ddd-a8f3-4d3e88e40d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/workspace/U-ViT')\n",
    "os.environ['PYTHONPATH'] = '/env/python:/content/U-ViT'\n",
    "\n",
    "import torch\n",
    "from dpm_solver_pp import NoiseScheduleVP, DPM_Solver\n",
    "import libs.autoencoder\n",
    "from libs.uvit import UViT\n",
    "import einops\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457d379-0e44-4127-ae70-75b1c0866985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modelscope.hub.file_download import model_file_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c518405-82c0-44b4-b0ea-1720b2838874",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = \"256\" #@param [256, 512]\n",
    "image_size = int(image_size)\n",
    "\n",
    "if image_size == 256:\n",
    "    model_file_download(model_id='thu-ml/imagenet256_uvit_huge',file_path='imagenet256_uvit_huge.pth', cache_dir='/mnt/workspace')\n",
    "    !mv /mnt/workspace/thu-ml/imagenet256_uvit_huge/imagenet256_uvit_huge.pth /mnt/workspace/U-ViT\n",
    "else:\n",
    "    model_file_download(model_id='thu-ml/imagenet512_uvit_huge',file_path='imagenet512_uvit_huge.pth', cache_dir='/mnt/workspace')\n",
    "    !mv /mnt/workspace/thu-ml/imagenet512_uvit_huge/imagenet512_uvit_huge.pth /mnt/workspace/U-ViT\n",
    " \n",
    "z_size = image_size // 8\n",
    "patch_size = 2 if image_size == 256 else 4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "nnet = UViT(img_size=z_size,\n",
    "       patch_size=patch_size,\n",
    "       in_chans=4,\n",
    "       embed_dim=1152,\n",
    "       depth=28,\n",
    "       num_heads=16,\n",
    "       num_classes=1001,\n",
    "       conv=False)\n",
    "\n",
    "nnet.to(device)\n",
    "nnet.load_state_dict(torch.load(f'imagenet{image_size}_uvit_huge.pth', map_location='cpu'))\n",
    "nnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3cf27-4593-4abc-9b27-6fd9e3507204",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file_download(model_id='AI-ModelScope/autoencoder_kl_ema',file_path='autoencoder_kl_ema.pth', cache_dir='/mnt/workspace')\n",
    "!mv /mnt/workspace/AI-ModelScope/autoencoder_kl_ema/autoencoder_kl_ema.pth /mnt/workspace/U-ViT\n",
    "autoencoder = libs.autoencoder.get_model('autoencoder_kl_ema.pth')\n",
    "autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b90cc-3884-44e3-87e3-ab3a0f0cd87d",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 4321 #@param {type:\"number\"}\n",
    "steps = 25 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "cfg_scale = 3 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
    "class_labels = 207, 360, 387, 974, 88, 979, 417, 279 #@param {type:\"raw\"}\n",
    "samples_per_row = 4 #@param {type:\"number\"}\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "def stable_diffusion_beta_schedule(linear_start=0.00085, linear_end=0.0120, n_timestep=1000):\n",
    "    _betas = (\n",
    "        torch.linspace(linear_start ** 0.5, linear_end ** 0.5, n_timestep, dtype=torch.float64) ** 2\n",
    "    )\n",
    "    return _betas.numpy()\n",
    "\n",
    "\n",
    "_betas = stable_diffusion_beta_schedule()  # set the noise schedule\n",
    "noise_schedule = NoiseScheduleVP(schedule='discrete', betas=torch.tensor(_betas, device=device).float())\n",
    "\n",
    "\n",
    "y = torch.tensor(class_labels, device=device)\n",
    "y = einops.repeat(y, 'B -> (B N)', N=samples_per_row)\n",
    "\n",
    "def model_fn(x, t_continuous):\n",
    "    t = t_continuous * len(_betas)\n",
    "    _cond = nnet(x, t, y=y)\n",
    "    _uncond = nnet(x, t, y=torch.tensor([1000] * x.size(0), device=device))\n",
    "    return _cond + cfg_scale * (_cond - _uncond)  # classifier free guidance\n",
    "\n",
    "\n",
    "z_init = torch.randn(len(y), 4, z_size, z_size, device=device)\n",
    "dpm_solver = DPM_Solver(model_fn, noise_schedule, predict_x0=True, thresholding=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "  with torch.cuda.amp.autocast():  # inference with mixed precision\n",
    "    z = dpm_solver.sample(z_init, steps=steps, eps=1. / len(_betas), T=1.)\n",
    "    samples = autoencoder.decode(z)\n",
    "samples = 0.5 * (samples + 1.)\n",
    "samples.clamp_(0., 1.)\n",
    "save_image(samples, \"sample.png\", nrow=samples_per_row * 2, padding=0)\n",
    "samples = Image.open(\"sample.png\")\n",
    "display(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
